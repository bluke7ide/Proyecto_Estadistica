---
title: "Proyecto Estadistica Actuarial I"
author: 
  - Estudiantes
  - Luis Fernando Amey Apuy - C20470
  - Anthony Jiménez Navarro - C24067
  - Javier Hernández Navarro - C13674
  - Erick Venegas Espinoza - C09319

date: "`r Sys.Date()`"
output: 
  rmdformats::downcute:
    default_style: "dark"
    downcute_theme: "chaos"
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```
# Librerías
```{r, warning=FALSE, message=FALSE}
# install.packages("zoo")
# install.packages("dplyr")
# install.packages("gtsummary")
# install.packages("pastecs")
# install.packages("summarytools")
# install.packages("ggplot2")
# install.packages("corrplot")
# install.packages("ggpubr")
# install.packages('xlsx')
# install.packages('knitr')

library(ggpubr)
library(zoo)
library(dplyr)
library(readxl)
library(gtsummary)
library(pastecs)
library(summarytools)
library(ggplot2)
library(corrplot)
library(xlsx)
library(knitr)
```

# Importación de datos
```{r}
# Se carga la base de datos principal
World_Data <- read_excel("data/World_Data.xlsx")

# Se clona
World_Data_2 <- World_Data

# Se carga la base de datos con los indices de felicidad
Tabla_Felicidad <- read_excel("data/DataForTable2.1 (1).xls")
```

# Análisis descriptivo
## Resumen
Se obtiene un summary de la base de datos principal
```{r}
summary(World_Data)
summary(Tabla_Felicidad)
```

## Limpieza de los datos
### Resumir la variable de año
Los valores que presenta la tabla de World_Data utiliza promedios que van desde el rango del 2015 al 2018, por lo que para proceder a trabajar Tabla_Felicidad, se hace un promedio de las variables agrupando con los países y se elimina la variable de año. Además, se calcula el promedio y se genera una nueva tabla únicamente con los promedios de las distintas variables
```{r}
Tabla_Felicidad_2 <- Tabla_Felicidad[
  Tabla_Felicidad$year >= 2015 & Tabla_Felicidad$year <= 2018, 
  ]

Tabla_Felicidad_2 <- Tabla_Felicidad_2 %>%
  group_by(`Country name`) %>%
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))

Tabla_Felicidad_2 <- Tabla_Felicidad_2 %>%
  select(-year)
```

### Eliminar variables repetidas
Se eliminan de World_Data_2 las variables "social_support", "freedom" y "generosity", esto con el fin de agregar los promedios obtenidos de Tabla_Felicidad_Reducida.
```{r}
World_Data_2 <- World_Data_2 %>%
  select(-social_support, -freedom, -generosity)
```

### Mezcla de las dos bases de datos
Se unen los dos dataframes, realizando una comparación entre "country" y "Country name", ademas se omiten los países que no cuentan con una entrada en Tabla_Felicidad_2
```{r}
World_Data_3 <- merge(World_Data_2,
                      Tabla_Felicidad_2,
                      by.x = "country",
                      by.y = "Country name")
```

### Limpieza NA
Se decide reemplazar los valores N/A presentes en distintas entradas por el promedio de la variable. Se van a contar los N/A después del procedimiento para asegurar de que no haya ninguno, y además se va a realizar un summary de esta. La existencia de valores N/A es debido a que no todos los países reportan todos los años a las tres entidades de las cuales se obtienen los datos, esto debido a las distintas dinámicas geo-socio-políticas que se desarrollan en las distintas divisiones geográficas del mundo, así como la calidad de las relaciones que existe entre los países, o situaciones de guerra o crisis.
```{r}
promedios <- sapply(World_Data_3,
                    function(x) if(is.numeric(x)) mean(x, na.rm = TRUE) else NA)
for (col in names(World_Data_3)) {
  World_Data_3[[col]][is.na(World_Data_3[[col]])] <- promedios[[col]]
}
colSums(is.na(World_Data_3))
rm(col)
rm(promedios)
```

Y se guarda el desc brevemente
```{r}
World_Data_3_Resumen = descr(World_Data_3)
write.xlsx(World_Data_3_Resumen, "docs/Estadisticas_Descriptivas.xlsx", row.names = TRUE)
```

### Transformación de la columna income_class

En la estructura que presenta "World_Data_3" se puede observar que cada variable va en una columna, no existe una combinación de distintas variables en la misma columna. A su vez cada observación es unica y sus valores estan distribuidos a lo largo de una unica fila Existe un identificador o key claro para cada una de las entradas, en este caso corresponde a la columna "country" que indica el país. Además queremos que todas las variables manejen valores numericos, asi que se va a reemplazar los valores de "income_class" por su factor, para de esta forma tener unicamente variables numericas. Ahora lo que vamos a realizar es un analisis descriptivo completo de la tabla, la forma mas sencilla de empezar este proceso es mediante la funcion "summary()", la cual permite obtener distintos estadísticos de la tabla en cuestión. Se procede a utilizar dicha funcion.

```{r}
World_Data_3 <- World_Data_3 %>%
  mutate(income_class = case_when(
    income_class == "Low income" ~ 0,
    income_class == "Lower middle income" ~ 1,
    income_class == "Upper middle income" ~ 2,
    income_class == "High income" ~ 3
  ))
```

### Haciendo las columnas en formato tidy
```{r}
colnames(World_Data_3) <- tolower(gsub(" ", "_", colnames(World_Data_3)))
```

### Eliminar la columna país

Además vamos a eliminar la columna de país, ya que queremos conseguir una correlación entre las distintas variables, esta no aporta utilidad en una escala mayor.

```{r}
Data_trabajar <- subset(World_Data_3, select = -country)
summary(Data_trabajar)
```

## Correlaciones

Con la data estructurada de la forma adecuada, podemos empezamos a buscar la relación existente entre los distintos marcadores con respecto a nuestro variable objetivo, en este caso "life_ladder". De la matriz de covarianza, podemos encontrar que tanta relación existe entre las distintas variables que forman la tabla, de forma que va a ser mas sencillo visualizar en que variables concentrar el estudio. Así como la de correlación, ya que al estar normalizada con valores que van desde -1 hasta 1, resulta mas sencilla observar las relaciones existentes. También se imprime el plot de correlaciones, ya que las dimensiones de Látex limitan la posibilidad de utilizar la matriz numérica.
```{r, message=FALSE, warning=FALSE, echo=FALSE}
write.xlsx(as.data.frame(cov(Data_trabajar)),
           "docs/Covarianza.xlsx", row.names = TRUE)
write.xlsx(as.data.frame(cor(Data_trabajar)),
           "docs/Correlacion.xlsx", row.names = TRUE)

pdf("docs/primeros_graficos/correlaciones.pdf") 
corrplot(cor(Data_trabajar), method = "circle", tl.cex = 0.5)
dev.off()

corrplot(cor(Data_trabajar), method = "circle", tl.cex = 0.5)
```

## Selección de variables relevantes
Ahora que tenemos el plot de correlación, seleccionamos las variables relevantes para el estudio, así que creamos un nuevo dataframe únicamente con las variables importantes, entre las que más se relacionan.

```{r}
Data_relevante = Data_trabajar %>% select (life_ladder,
                                           electricity_access,
                                           water_access, 
                                           income_class,
                                           cpi,
                                           log_gdp_per_capita)
```

## Descripción de variables relevantes
Vamos a realizar varios estadísticos breves para las variables escogidas
```{r}
life_ladder_table <- data.frame(
  Valor = c(summary(Data_relevante$life_ladder),
            sd(Data_trabajar$life_ladder))
)
row.names(life_ladder_table) <- c("Mínimo",
                                  "1° Cuartil",
                                  "Mediana",
                                  "Media",
                                  "3° Cuartil",
                                  "Máximo",
                                  "Desviación Estándar")
print(life_ladder_table)
```

```{r}
log_gdp_table <- data.frame(
  Valor = c(summary(Data_relevante$log_gdp_per_capita),
            sd(Data_trabajar$log_gdp_per_capita))
)
row.names(log_gdp_table) <- c("Mínimo",
                              "1° Cuartil",
                              "Mediana",
                              "Media",
                              "3° Cuartil",
                              "Máximo",
                              "Desviación Estándar")
print(log_gdp_table)
```

```{r}
write.xlsx(life_ladder_table, "docs/life_ladder_table.xlsx", row.names = TRUE)
write.xlsx(log_gdp_table, "docs/log_gdp_table.xlsx", row.names = TRUE)
```

## Gráfico de los datos selectos

Se van a desarrollar graficos con el fin de estudiar el comportamiento de los datos selectos

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plots <- list()
plots[[1]] <- ggplot(Data_relevante, aes(x = life_ladder)) +
  geom_histogram(aes(y = after_stat(density), fill = "Histograma"), 
                 color = "black", bins = 30) +
  geom_density(aes(fill = "Densidad"), 
               color = "royalblue", 
               alpha = 0.4) +
  geom_function(fun = function(t) dnorm(x = t,
                                        mean = mean(Data_relevante$life_ladder),
                                        sd = sd(Data_relevante$life_ladder)),
                aes(color = "Normal con parámetros de life_ladder"),
                linewidth = 1.5,
                alpha = 0.5) + 
  labs(title = "Histograma de life_ladder",
       x = "Valores", 
       y = "Densidad",
       color = " ",
       fill = " ") +
  xlim(0, 10) +
  scale_fill_manual(values = c("blue", "lightblue")) +
  scale_color_manual(values = c("darkorange3")) +
  theme_minimal() + 
  theme(legend.position = 'bottom')
  
plots[[2]] <- ggscatter(
  Data_relevante, 
  x = "electricity_access", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "orange1",
  add.params = list(color = "gray20"),  
  title = "Gráfico de electricity_access vs life_ladder",
  xlab = "electricity_access",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[3]] <- ggscatter(
  Data_relevante, 
  x = "water_access", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "darkorange",
  add.params = list(color = "gray20"),  
  title = "Gráfico de water_access vs life_ladder",
  xlab = "water_access",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)


plots[[4]] <- ggplot(Data_relevante, aes(group = income_class,
                           x = income_class,
                           y = life_ladder,
                           fill = income_class)) +
  geom_boxplot(staplewidth = 0.1) +
  labs(title = "Grafico de income_class vs life_ladder",
       x = "income_class", 
       y ="life_ladder") +
  theme_minimal()

plots[[5]] <- ggscatter(
  Data_relevante, 
  x = "cpi", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "orangered",
  add.params = list(color = "gray20"),  
  title = "Gráfico de cpi vs life_ladder",
  xlab = "cpi",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[6]] <- ggscatter(
  Data_relevante,
  x = "log_gdp_per_capita", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "darkred",
  add.params = list(color = "gray20"),  
  title = "Gráfico de log_gdp_per_capita vs life_ladder",
  xlab = "log_gdp_per_capita",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[1]]
plots[[2]]
plots[[3]]
plots[[4]]
plots[[5]]
plots[[6]]

ggsave("docs/segundos_graficos/life_ladder.pdf", plot = plots[[1]])
ggsave("docs/segundos_graficos/elec_life.pdf", plot = plots[[2]])
ggsave("docs/segundos_graficos/water_life.pdf", plot = plots[[3]])
ggsave("docs/segundos_graficos/income_life.pdf", plot = plots[[4]])
ggsave("docs/segundos_graficos/cpi_life.pdf", plot = plots[[5]])
ggsave("docs/segundos_graficos/lgdp_life.pdf", plot = plots[[6]])
rm(plots)
```

# Análisis de comportamientos
## Correlaciones y Shapiro test
Obtenemos la correlación utilizando distintos métodos, en este caso Pearson, Kendall y Spearman, vamos a concentrarnos en Pearson, pero los otros métodos nos permite tener una idea mas clara del comportamiento de los datos.
```{r}
res <- cor.test(Data_relevante$log_gdp_per_capita,
                Data_relevante$life_ladder,
                method=c("pearson", "kendall", "spearman"))
print(paste("Valor-p: ",res$p.value))
print(paste("correlación:", res$estimate))
```
Prueba de normalidad Shapiro-Wilk de las variables
```{r}
shapiro.test(Data_relevante$life_ladder) 
shapiro.test(Data_relevante$log_gdp_per_capita)
```

## Gráficos relevantes
```{r}
qqplots_a <- ggqqplot(Data_relevante$life_ladder, 
                      ylab = "life_ladder") +
  labs(title = "Gráfico de cuantiles de life_ladder") +
  theme_minimal() +
  ylim(0, 10) +
  geom_qq(colour = "mediumseagreen")

qqplots_b <- ggqqplot(Data_relevante$log_gdp_per_capita, 
                      ylab = "life_ladder") +
  labs(title = "Gráfico de cuantiles de log_gdp_per_capita") +
  theme_minimal() +
  ylim(0, 15) +
  geom_qq(colour = "#006400")

qqplots_a
qqplots_b

ggsave("docs/terceros_graficos/qqp_life.pdf", plot = qqplots_a, limitsize = FALSE)
ggsave("docs/terceros_graficos/qqp_lgdp.pdf", plot = qqplots_b, limitsize = FALSE)
```

# Metodo Delta Multivariable

## log_gdp_per_capita
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "log_gdp_per_capita"
Y <- Data_relevante$life_ladder
X <- Data_relevante$log_gdp_per_capita
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlacion
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Funcion g
funcion_g <- atan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)

rm(Tabla_Resultados)
# Tabla con resultados
# Create the data frame
Tabla_Resultados <- data.frame(
  "Predictor" = "log_gdp_per_capita",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
)
```

## electricity_access
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "electricity_access"
Y <- Data_relevante$life_ladder
X <- Data_relevante$electricity_access
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlacion
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Funcion g
funcion_g <- atan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "electricity_access",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))
```

## water_access
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "water_access"
Y <- Data_relevante$life_ladder
X <- Data_relevante$water_access
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlacion
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Funcion g
funcion_g <- atan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "water_access",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))
```

## cpi
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "cpi"
Y <- Data_relevante$life_ladder
X <- Data_relevante$cpi
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlacion
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Funcion g
funcion_g <- atan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g

z_conf_int <- z + c(-1, 1) * qnorm(0.975) * 1 / sqrt(n - 3)
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "cpi",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))

print(Tabla_Resultados)
```

# Normalización

Vamos a normalizar el comportamiento de la variable life_ladder, mediante el uso del Teorema del Límite Central

```{r}
# Obtenemos los parametros necesarios para conseguir la normal de life_ladder
Y_promedio <- mean(Y)
Y_sd <- sd(Y)

Y_normalizada = dnorm(Y, Y_promedio, Y_sd)

df_graficar <- data.frame(Life_Ladder = Y, Density = Y_normalizada)

ggplot(df_graficar, aes(x = Life_Ladder, y = Density)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(title = "life_ladder Normalizada",
       x = "Life Ladder",
       y = "Densidad") +
  theme_minimal()
```

```{r}
ystd <- data.frame(norm = (Y - Y_promedio)/Y_sd)

ggplot(ystd, aes(x = norm)) +
  geom_histogram(aes(y = after_stat(density), fill = "Histograma"), 
                 color = "black", bins = 30) +
  geom_density(aes(fill = "Densidad"), 
               color = "royalblue", 
               alpha = 0.4) +
  geom_function(fun = dnorm,
                aes(color = "Normal(0,1)"),
                linewidth = 1.5,
                alpha = 0.5) + 
  labs(title = "Histograma de life_ladder estandarizada ",
       x = "Valores", 
       y = "Densidad",
       color = " ",
       fill = " ") +
  scale_fill_manual(values = c("blue", "lightblue")) +
  scale_color_manual(values = c("darkorange3")) +
  xlim(-3,3) +
  theme_minimal() + 
  theme(legend.position = 'bottom')
```

