---
title: "Proyecto Estadistica Actuarial I"
author: 
  - Estudiantes
  - Luis Fernando Amey Apuy - C20470
  - Anthony Jiménez Navarro - C24067
  - Javier Hernández Navarro - C13674
  - Erick Venegas Espinoza - C09319

date: "`r Sys.Date()`"
output: 
  rmdformats::downcute:
    default_style: "dark"
    downcute_theme: "chaos"
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

# Librerías
```{r, warning=FALSE, message=FALSE}
# install.packages("zoo")
# install.packages("dplyr")
# install.packages("gtsummary")
# install.packages("pastecs")
# install.packages("summarytools")
# install.packages("ggplot2")
# install.packages("corrplot")
# install.packages("ggpubr")
# install.packages('openxlsx')
# install.packages('knitr')

library(ggpubr)
library(zoo)
library(dplyr)
library(readxl)
library(gtsummary)
library(pastecs)
library(summarytools)
library(ggplot2)
library(corrplot)
library(openxlsx)
library(knitr)
```

# Carga de datos
## Importación de los datos
```{r}
# Se carga la base de datos principal
World_Data <- read_excel("data/World_Data.xlsx")

# Se clona
World_Data_2 <- World_Data

# Se carga la base de datos con los indices de felicidad
Tabla_Felicidad <- read_excel("data/DataForTable2.1 (1).xls")
```

## Limpieza de los datos
### Resumir la variable de año
Los valores que presenta la tabla de World_Data utiliza promedios que van desde el rango del 2015 al 2018, por lo que para proceder a trabajar Tabla_Felicidad, se hace un promedio de las variables agrupando con los países y se elimina la variable de año. Además, se calcula el promedio y se genera una nueva tabla únicamente con los promedios de las distintas variables
```{r}
Tabla_Felicidad_2 <- Tabla_Felicidad[
  Tabla_Felicidad$year >= 2015 & Tabla_Felicidad$year <= 2018, 
  ]

Tabla_Felicidad_2 <- Tabla_Felicidad_2 %>%
  group_by(`Country name`) %>%
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))

Tabla_Felicidad_2 <- Tabla_Felicidad_2 %>%
  select(-year)
```

### Eliminar variables repetidas
Se eliminan de World_Data_2 las variables "social_support", "freedom" y "generosity", esto con el fin de agregar los promedios obtenidos de Tabla_Felicidad_Reducida.
```{r}
World_Data_2 <- World_Data_2 %>%
  select(-social_support, -freedom, -generosity)
```

### Mezcla de las dos bases de datos
Se unen los dos dataframes, realizando una comparación entre "country" y "Country name", ademas se omiten los países que no cuentan con una entrada en Tabla_Felicidad_2
```{r}
World_Data_3 <- merge(World_Data_2,
                      Tabla_Felicidad_2,
                      by.x = "country",
                      by.y = "Country name")
```

### Limpieza NA
Se decide reemplazar los valores N/A presentes en distintas entradas por el promedio de la variable. Se van a contar los N/A después del procedimiento para asegurar de que no haya ninguno, y además se va a realizar un summary de esta. La existencia de valores N/A es debido a que no todos los países reportan todos los años a las tres entidades de las cuales se obtienen los datos, esto debido a las distintas dinámicas geo-socio-políticas que se desarrollan en las distintas divisiones geográficas del mundo, así como la calidad de las relaciones que existe entre los países, o situaciones de guerra o crisis.
```{r}
promedios <- sapply(World_Data_3,
                    function(x) if(is.numeric(x)) mean(x, na.rm = TRUE) else NA)
for (col in names(World_Data_3)) {
  World_Data_3[[col]][is.na(World_Data_3[[col]])] <- promedios[[col]]
}
colSums(is.na(World_Data_3))
rm(col)
rm(promedios)
```

### Transformación de la columna income_class
En la estructura que presenta "World_Data_3" se puede observar que cada variable va en una columna, no existe una combinación de distintas variables en la misma columna. A su vez cada observación es única y sus valores están distribuidos a lo largo de una única fila. Existe un identificador o key claro para cada una de las entradas, en este caso corresponde a la columna "country" que indica el país. Además queremos que todas las variables manejen valores numéricos, así que se va a reemplazar los valores de "income_class" por su factor, para de esta forma tener únicamente variables numéricas. Ahora lo que vamos a realizar es un análisis descriptivo completo de la tabla, la forma mas sencilla de empezar este proceso es mediante la función "summary()", la cual permite obtener distintos estadísticos de la tabla en cuestión. Se procede a utilizar dicha función.
```{r}
World_Data_3 <- World_Data_3 %>%
  mutate(income_class = case_when(
    income_class == "Low income" ~ 0,
    income_class == "Lower middle income" ~ 1,
    income_class == "Upper middle income" ~ 2,
    income_class == "High income" ~ 3
  ))
```

### Haciendo las columnas en formato tidy
```{r}
colnames(World_Data_3) <- tolower(gsub(" ", "_", colnames(World_Data_3)))
```

### Eliminar la columna país
Además vamos a eliminar la columna de país, ya que queremos conseguir una correlación entre las distintas variables, esta no aporta utilidad en una escala mayor.
```{r}
Data_trabajar <- subset(World_Data_3, select = -country)
```

# Análisis descriptivo
## Resumen
Se obtiene un resumen de la base de datos principal sin modificar por medio de summary()
```{r}
summary(World_Data)
summary(Tabla_Felicidad)
```

Se guarda el desc brevemente de la base de datos conjunta
```{r}
World_Data_3_Resumen = descr(World_Data_3)
write.xlsx(World_Data_3_Resumen,
           "docs/Estadisticas_Descriptivas.xlsx", rowNames = TRUE)
```

Y un summary breve después de la modificación de la base de datos
```{r}
summary(Data_trabajar)
```

## Correlaciones
Con la data estructurada de la forma adecuada, podemos empezamos a buscar la relación existente entre los distintos marcadores con respecto a nuestro variable objetivo, en este caso "life_ladder". De la matriz de covarianza, podemos encontrar que tanta relación existe entre las distintas variables que forman la tabla, de forma que va a ser mas sencillo visualizar en que variables concentrar el estudio. Así como la de correlación, ya que al estar normalizada con valores que van desde -1 hasta 1, resulta mas sencilla observar las relaciones existentes. También se imprime el plot de correlaciones, ya que las dimensiones de Látex limitan la posibilidad de utilizar la matriz numérica.
```{r, message=FALSE, warning=FALSE, echo=FALSE}
write.xlsx(as.data.frame(cov(Data_trabajar)),
           "docs/Covarianza.xlsx", rowNames = TRUE)
write.xlsx(as.data.frame(cor(Data_trabajar)),
           "docs/Correlacion.xlsx", rowNames = TRUE)

pdf("docs/primeros_graficos/correlaciones.pdf") 
corrplot(cor(Data_trabajar), method = "circle", tl.cex = 0.5)
dev.off()

corrplot(cor(Data_trabajar), method = "circle", tl.cex = 0.5)
```

## Selección de variables relevantes
Ahora que tenemos el plot de correlación, seleccionamos las variables relevantes para el estudio, así que creamos un nuevo dataframe únicamente con las variables importantes, entre las que más se relacionan.
```{r}
Data_relevante = Data_trabajar %>% select (life_ladder,
                                           electricity_access,
                                           water_access, 
                                           income_class,
                                           cpi,
                                           log_gdp_per_capita)
```

## Descripción de variables relevantes
Vamos a realizar varios estadísticos breves para las variables de importancia
```{r}
life_ladder_table <- data.frame(
  Valor = c(summary(Data_relevante$life_ladder),
            sd(Data_trabajar$life_ladder))
)
row.names(life_ladder_table) <- c("Mínimo",
                                  "1° Cuartil",
                                  "Mediana",
                                  "Media",
                                  "3° Cuartil",
                                  "Máximo",
                                  "Desviación Estándar")
print(life_ladder_table)
```

```{r}
log_gdp_table <- data.frame(
  Valor = c(summary(Data_relevante$log_gdp_per_capita),
            sd(Data_trabajar$log_gdp_per_capita))
)
row.names(log_gdp_table) <- c("Mínimo",
                              "1° Cuartil",
                              "Mediana",
                              "Media",
                              "3° Cuartil",
                              "Máximo",
                              "Desviación Estándar")
print(log_gdp_table)
```
Y las guardamos
```{r}
write.xlsx(life_ladder_table, "docs/life_ladder_table.xlsx", rowNames = TRUE)
write.xlsx(log_gdp_table, "docs/log_gdp_table.xlsx", rowNames = TRUE)
```


# Ajuste completo del modelo
## Coeficiente de Correlación de Pearson
Se van a desarrollar gráficos con el fin de estudiar el comportamiento de los datos selectos, además se agrega el coeficiente de correlación de Pearson para tener claro el nivel de relación existente entre las variables, además se calcula el valor-p el cual nos permite realizar pruebas de hipótesis, en este caso establecer una correlación, en caso de ser menor al usual 0.05 aceptamos la correlación obtenida.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
plots <- list()
plots[[1]] <- ggplot(Data_relevante, aes(x = life_ladder)) +
  geom_histogram(aes(y = after_stat(density), fill = "Histograma"), 
                 color = "black", bins = 30) +
  geom_density(aes(fill = "Densidad"), 
               color = "royalblue", 
               alpha = 0.4) +
  geom_function(fun = function(t) dnorm(x = t,
                                        mean = mean(Data_relevante$life_ladder),
                                        sd = sd(Data_relevante$life_ladder)),
                aes(color = "Normal con parámetros de life_ladder"),
                linewidth = 1.5,
                alpha = 0.5) + 
  labs(title = "Histograma de life_ladder",
       x = "Valores", 
       y = "Densidad",
       color = " ",
       fill = " ") +
  xlim(0, 10) +
  scale_fill_manual(values = c("blue", "lightblue")) +
  scale_color_manual(values = c("darkorange3")) +
  theme_minimal() + 
  theme(legend.position = 'bottom')
  
plots[[2]] <- ggscatter(
  Data_relevante, 
  x = "electricity_access", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "orange1",
  add.params = list(color = "gray20"),  
  title = "Gráfico de electricity_access vs life_ladder",
  xlab = "electricity_access",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[3]] <- ggscatter(
  Data_relevante, 
  x = "water_access", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "darkorange",
  add.params = list(color = "gray20"),  
  title = "Gráfico de water_access vs life_ladder",
  xlab = "water_access",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)


plots[[4]] <- ggplot(Data_relevante, aes(group = income_class,
                           x = income_class,
                           y = life_ladder,
                           fill = income_class)) +
  geom_boxplot(staplewidth = 0.1) +
  labs(title = "Grafico de income_class vs life_ladder",
       x = "income_class", 
       y ="life_ladder") +
  theme_minimal()

plots[[5]] <- ggscatter(
  Data_relevante, 
  x = "cpi", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "orangered",
  add.params = list(color = "gray20"),  
  title = "Gráfico de cpi vs life_ladder",
  xlab = "cpi",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[6]] <- ggscatter(
  Data_relevante,
  x = "log_gdp_per_capita", 
  y = "life_ladder",
  add = "reg.line", 
  cor.coef = TRUE, 
  conf.int = TRUE,
  cor.method = "pearson", 
  cor.coeff.args = list(label.sep = "\n"), 
  color = "darkred",
  add.params = list(color = "gray20"),  
  title = "Gráfico de log_gdp_per_capita vs life_ladder",
  xlab = "log_gdp_per_capita",
  ylab = "life_ladder") +
  theme_minimal() +
  ylim(0,8)

plots[[1]]
plots[[2]]
plots[[3]]
plots[[4]]
plots[[5]]
plots[[6]]

ggsave("docs/segundos_graficos/life_ladder.pdf", plot = plots[[1]])
ggsave("docs/segundos_graficos/elec_life.pdf", plot = plots[[2]])
ggsave("docs/segundos_graficos/water_life.pdf", plot = plots[[3]])
ggsave("docs/segundos_graficos/income_life.pdf", plot = plots[[4]])
ggsave("docs/segundos_graficos/cpi_life.pdf", plot = plots[[5]])
ggsave("docs/segundos_graficos/lgdp_life.pdf", plot = plots[[6]])
rm(plots)
```

Con valores de p inferiores al 0.05 en todos los casos se acepta la hipótesis de que existe una correlación positiva entre los distintos marcadores del progreso socioeconómico (1) log_gdp_per_capita, (2) electricity_access, (3) water_access, (4) cpi, con respecto a la variable de estudio life_ladder

## Correlaciones y Shapiro test
### Métodos de Pearson, Kendall y Spearman
Obtenemos la correlación utilizando distintos métodos, en este caso Pearson, Kendall y Spearman, vamos a concentrarnos en Pearson, pero los otros métodos nos permite tener una idea mas clara del comportamiento de los datos.
```{r}
res <- cor.test(Data_relevante$log_gdp_per_capita,
                Data_relevante$life_ladder,
                method=c("pearson", "kendall", "spearman"))
print(paste("Valor-p: ",res$p.value))
print(paste("correlación:", res$estimate))
```

### Prueba de normalidad Shapiro-Wilk de las variables
```{r}
shapiro.test(Data_relevante$life_ladder) 
shapiro.test(Data_relevante$log_gdp_per_capita)
```

### Gráficos relevantes a la prueba anterior
```{r}
qqplots_a <- ggqqplot(Data_relevante$life_ladder, 
                      ylab = "life_ladder") +
  labs(title = "Gráfico de cuantiles de life_ladder") +
  theme_minimal() +
  ylim(0, 10) +
  geom_qq(colour = "mediumseagreen")

qqplots_b <- ggqqplot(Data_relevante$log_gdp_per_capita, 
                      ylab = "life_ladder") +
  labs(title = "Gráfico de cuantiles de log_gdp_per_capita") +
  theme_minimal() +
  ylim(0, 15) +
  geom_qq(colour = "#006400")

qqplots_a
qqplots_b

ggsave("docs/terceros_graficos/qqp_life.pdf", plot = qqplots_a, limitsize = FALSE)
ggsave("docs/terceros_graficos/qqp_lgdp.pdf", plot = qqplots_b, limitsize = FALSE)
```

En los gráficos se puede apreciar la forma en la que se distribuye las distribuciones y su relación con una distribución normal

## Metodo Delta Multivariable y Transformación Z de Fisher
Para cada uno de los predictores siguientes se decide realizar el calculo de la covarianza y varianzas requeridas para obtener la correlación, además de esto se obtiene el coeficiente de regresión. Seguido de esto se realiza la transformación Z de Fisher para calcular los intervalos de confianza de la correlación obtenida.

### log_gdp_per_capita
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "log_gdp_per_capita"
Y <- Data_relevante$life_ladder
X <- Data_relevante$log_gdp_per_capita
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlación
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Función g
funcion_g <- tan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975, mean = 0, sd = 1) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)

Tabla_Resultados <- data.frame(
  "Predictor" = "log_gdp_per_capita",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
)

```

### electricity_access
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "electricity_access"
Y <- Data_relevante$life_ladder
X <- Data_relevante$electricity_access
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlación
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Función g
funcion_g <- tan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975, 0, 1) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "electricity_access",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))

```

### water_access
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "water_access"
Y <- Data_relevante$life_ladder
X <- Data_relevante$water_access
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlación
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Función g
funcion_g <- tan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g
sd_z <- 1 / sqrt(n - 3)

z_conf_int <- z + c(-1, 1) * qnorm(0.975, 0, 1) * sd_z
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "water_access",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))

```

### cpi
```{r}
# Se establece la variable a predecir "life_ladder" y la predictora "cpi"
Y <- Data_relevante$life_ladder
X <- Data_relevante$cpi
XY <- X*Y
X_2 <- X*X
n <- length(Data_relevante$life_ladder)

# Covarianza y varianzas
valor_cov <- cov(X, Y)
var_X <- var(X)
var_Y <- var(Y)

# Correlación
cor = valor_cov/(sqrt(var_X * var_Y))

# Promedios
XY_promedio <- mean(XY)
X_promedio <- mean(X)
Y_promedio <- mean(Y)
X_2_promedio <- mean(X_2)

rn <- (XY_promedio - X_promedio * Y_promedio) / (sqrt(X_2_promedio - X_promedio^2))

# Función g
funcion_g <- tan(cor)
funcion_g_prima <- 1/(1-cor^2)

# TLC
tlc <- sqrt(n) * (rn - cor) / (1 - cor^2)

# Transformación de Fisher
z = funcion_g

z_conf_int <- z + c(-1, 1) * qnorm(0.975, 0, 1) * 1 / sqrt(n - 3)
cor_conf_int <- (exp(2 * z_conf_int) - 1) / (exp(2 * z_conf_int) + 1)


Tabla_Resultados <- rbind(Tabla_Resultados, data.frame(
  "Predictor" = "cpi",
  "Correlación" = cor,
  "Coeficiente de Regresión" = rn,
  "IC Inferior Correlación" = cor_conf_int[1],
  "IC Superior Correlación" = cor_conf_int[2]
))

print(Tabla_Resultados)
```

Se crea una tabla de resultados con el fin de poder analizar los resultados obtenidas de forma sencilla y agrupada, se puede observar que los coeficientes de correlación presentan un alto grado de relación con respecto a la variable de estudio, además de encontrarse presentes en el rango del Intervalo de Confianza. Lo que se quería demostrar era la relación existente entre los marcadores socio-económicos y el indice de Felicidad, con los resultados obtenidos podemos afirmar que existe una relación positiva.

# Análisis de diagnósticos del Modelo
## Residuales
Se crea un modelo de regresión lineal entra las variables predictoras y la predecida con el fin de obtener los residuales y evaluar la efectividad del método Shapiro-Wilks
```{r}
modelo_gdp <- lm(life_ladder ~ log_gdp_per_capita, data = Data_relevante)
modelo_electricity <- lm(life_ladder ~ electricity_access, data = Data_relevante)
modelo_water <- lm(life_ladder ~ water_access, data = Data_relevante)
modelo_cpi <- lm(life_ladder ~ cpi, data = Data_relevante)

# Gráfico de diagnostico de residuales
par(mfrow = c(2, 2))
plot(modelo_gdp)
plot(modelo_electricity)
plot(modelo_water)
plot(modelo_cpi)

# Comprobar si los residuos se distribuyen de forma normal
shapiro.test(resid(modelo_gdp))
shapiro.test(resid(modelo_electricity))
shapiro.test(resid(modelo_water))
shapiro.test(resid(modelo_cpi))
```

Los gráficos nos permiten estudiar el comportamiento de distintos parámetros de los modelos:
(1) Residuals vs Fitted: Nos permite detectar problemas de no linealidad, heterocedasticidad o outliers
(2) Normal Q-Q: Permite evaluar la normalidad de los residuales
(3) Scale-Location: Verifica la homocedasticidad
(4) Residuals vs Leverage: Identifica puntos influyentes

A su vez el test de normalidad de Shapiro-Wilk de los residuos nos permite observar si se da un comportamiento Normal de los residuos.

## Normalización

Vamos a normalizar el comportamiento de la variable life_ladder, mediante el uso del Teorema del Límite Central
```{r}
Y_promedio <- mean(Y)
Y_sd <- sd(Y)
ystd <- data.frame(norm = (Y - Y_promedio)/Y_sd)

ggplot(ystd, aes(x = norm)) +
  geom_histogram(aes(y = after_stat(density), fill = "Histograma"), 
                 color = "black", bins = 30) +
  geom_density(aes(fill = "Densidad"), 
               color = "royalblue", 
               alpha = 0.4) +
  geom_function(fun = dnorm,
                aes(color = "Normal(0,1)"),
                linewidth = 1.5,
                alpha = 0.5) + 
  labs(title = "Histograma de life_ladder estandarizada ",
       x = "Valores", 
       y = "Densidad",
       color = " ",
       fill = " ") +
  scale_fill_manual(values = c("blue", "lightblue")) +
  scale_color_manual(values = c("darkorange3")) +
  xlim(-3,3) +
  theme_minimal() + 
  theme(legend.position = 'bottom')
```

